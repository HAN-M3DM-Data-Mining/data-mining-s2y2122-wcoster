---
title: "Lazy Learning with K"
author: "Willem"
output: html_notebook
---

##### Code loading in the essential packages
```{r}
library(magrittr) # needs to be run every time you start R and want to use %>%
library(dplyr)    # alternatively, this also loads %>%
library(caret)
library(tidyverse)
library(class)
```

##### Getting the data and putting it in variable "rawDF"
```{r}
url <- "https://raw.githubusercontent.com/businessdatasolutions/courses/main/data%20mining/gitbook/datasets/breastcancer.csv"
rawDF <- read_csv(url)
```

```{r}
str(rawDF)
```
 
# 2.3 preparation
```{r}
cleanDF <- rawDF[-1]
head(cleanDF)
```

```{r}
cntDiag <- table(cleanDF$diagnosis)
propDiag <- round(prop.table(cntDiag) * 100 , digits = 1)

cntDiag
```

```{r}
propDiag
```


```{r}
cleanDF$diagnosis <- factor(cleanDF$diagnosis, levels = c("B", "M"), labels = c("Benign", "Malignant")) %>% relevel("Malignant")
head(cleanDF, 10)
```

```{r}
summary(cleanDF[c("radius_mean", "area_mean", "smoothness_mean")])
```

```{r}
normalize <- function(x) { # Function takes in a vector
  return ((x - min(x)) / (max(x) - min(x))) # distance of item value - minimum vector value divided by the range of all vector values
}

testSet1 <- c(1:5)
testSet2 <- c(1:5) * 10

cat("testSet1:", testSet1, "\n")
```

```{r}
cat("testSet2:", testSet2, "\n")
```

```{r}
cat("Normalized testSet1:", normalize(testSet1), "\n")
```

```{r}
cat("Normalized testSet2:", normalize(testSet2))
```

```{r}
nCols <- dim(cleanDF)[2]
cleanDF_n <- sapply(2:nCols,
                    function(x) {
  normalize(cleanDF[,x])
}) %>% as.data.frame()

summary(cleanDF_n[c("radius_mean", "area_mean", "smoothness_mean")])
```

```{r}
trainDF_feat <- cleanDF_n[1:469,  ]
testDF_feat <- cleanDF_n[470:569,  ]

trainDF_labels <- cleanDF[1:469,  1]
testDF_labels <- cleanDF[470:569,  1]
```

# 2.4 Modeling and Evaluation
```{r}
cleanDF_test_pred <- knn(train = as.matrix(trainDF_feat), test = as.matrix(testDF_feat), cl = as.matrix(trainDF_labels), k = 21)
head(cleanDF_test_pred)
```

```{r}
confusionMatrix(cleanDF_test_pred, testDF_labels[[1]], positive = NULL, dnn = c("Prediction", "True"))
```

# Questions:
<b>How would you assess the overall performance of the model?</b>

<i> The model is according to the confusion matrix 98% accurate, which I would consider a very high score. Although, when a cancerous tumor is diagnosed as benign while it is malignant the consequences are too great for the 2% failure. </i>

<b>What would you consider as more costly: high false negatives or high false positives levels? Why?</b>

<i> Honestly no idea</i>